{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805750f2-421d-43eb-b923-8f1788df630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency, ttest_ind\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.stats import chisquare\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "df = pd.read_csv('final_data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06b579f-7ec2-49ac-9ac9-43f36268eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the Date column is in datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Extract the year and create a new column\n",
    "df['Year'] = df['Date'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a37d5ce-0847-4666-ad67-ac5c7eb90813",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# Hypothesis 1: Genres are linked to specific topics\n",
    "def test_genre_topic_association(df):\n",
    "    # Create a contingency table for genres and topics\n",
    "    contingency_table = pd.crosstab(df['Final_genre'], df['Topic_label'])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "    print(f\"Chi-square test for genre-topic association:\\nChi2 Statistic: {chi2}, p-value: {p}\")\n",
    "    return p < 0.05\n",
    "\n",
    "\n",
    "print(\"Hypothesis 1:\", \"Supported\" if test_genre_topic_association(df) else \"Not Supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51b00f-c580-4d9d-902a-a785d9902120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 2: There are more profanities used now than in the 90s\n",
    "\n",
    "\n",
    "def test_profanity_over_time(df):\n",
    "    # Label decades\n",
    "    df['decade'] = np.where(df['Year'] < 2000, '90s', 'Recent')\n",
    "    \n",
    "    # Calculate mean of 'Has_swear' by decade (proportion of songs with profanity)\n",
    "    profanity_proportion = df.groupby('decade')['has_swear'].mean()\n",
    "    \n",
    "    # Perform t-test to compare the 90s with Recent decades\n",
    "    t_stat, p = ttest_ind(\n",
    "        df[df['decade'] == '90s']['has_swear'], \n",
    "        df[df['decade'] == 'Recent']['has_swear']\n",
    "    )\n",
    "    \n",
    "    print(\"Proportion of songs with profanity by decade:\\n\", profanity_proportion)\n",
    "    print(\"T-statistic:\", t_stat, \"P-value:\", p)\n",
    "    \n",
    "    # Return whether profanity increased over time\n",
    "    return p < 0.05 and profanity_proportion['Recent'] > profanity_proportion['90s']\n",
    "\n",
    "\n",
    "print(\"Hypothesis 2:\", \"Supported\" if test_profanity_over_time(df) else \"Not Supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1820ab-20de-43f6-90bc-0488590009b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 3: Hip Hop/Rap songs have richer vocabulary\n",
    "def test_vocabulary_richness(df):\n",
    "    # Filter to Hip Hop/Rap and other genres, then compare unique words\n",
    "    df_hiphop = df[df['Final_genre'] == 'Hip Hop/Rap']\n",
    "    df_other = df[df['Final_genre'] != 'Hip Hop/Rap']\n",
    "    t_stat, p = ttest_ind(df_hiphop['Unique_words'], df_other['Unique_words'])\n",
    "    print(f\"T-test for vocabulary richness in Hip Hop/Rap:\\nT Statistic: {t_stat}, p-value: {p}\")\n",
    "    return p < 0.05\n",
    "\n",
    "print(\"Hypothesis 3:\", \"Supported\" if test_vocabulary_richness(df) else \"Not Supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bb27a2-bce8-4fce-ab64-dbba16c719a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypothesis 4: Pop songs are more often about love and loss than other genres\n",
    "\n",
    "def test_love_and_loss_songs_pop_vs_others(df):\n",
    "    # Count songs labeled as \"Love and Loss\" for each genre\n",
    "    pop_love_loss_count = df[(df['Final_genre'].str.lower() == 'pop') & (df['Topic_label'] == 'Love and Loss')].shape[0]\n",
    "    other_love_loss_count = df[(df['Final_genre'].str.lower() != 'pop') & (df['Topic_label'] == 'Love and Loss')].shape[0]\n",
    "\n",
    "    # Count total songs for pop and other genres\n",
    "    total_pop_count = df[df['Final_genre'].str.lower() == 'pop'].shape[0]\n",
    "    total_other_count = df[df['Final_genre'].str.lower() != 'pop'].shape[0]\n",
    "\n",
    "    # Prepare data for the proportion test\n",
    "    counts = [pop_love_loss_count, other_love_loss_count]\n",
    "    nobs = [total_pop_count, total_other_count]\n",
    "\n",
    "    # Perform proportion z-test\n",
    "    z_stat, p_value = proportions_ztest(counts, nobs)\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"Pop 'Love and Loss' Count: {pop_love_loss_count}, Other Genres 'Love and Loss' Count: {other_love_loss_count}\")\n",
    "    print(f\"Z-statistic: {z_stat}, p-value: {p_value}\")\n",
    "\n",
    "    # Results interpretation\n",
    "    if p_value < 0.05:\n",
    "        print(\"There are significantly more love songs about 'Love and Loss' in pop than in other genres.\")\n",
    "    else:\n",
    "        print(\"There is no significant difference in the number of love songs about 'Love and Loss' in pop compared to other genres.\")\n",
    "\n",
    "# Example usage:\n",
    "# Ensure your DataFrame `df` is properly formatted\n",
    "test_love_and_loss_songs_pop_vs_others(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b735cd-cd11-465b-9ae9-784c4f462b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8276944-7c2b-425a-a560-129341d5a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 1: Genres are linked to specific topics\n",
    "def test_genre_topic_association(df):\n",
    "    # Create a contingency table for genres and topics\n",
    "    contingency_table = pd.crosstab(df['Final_genre'], df['Topic_label'])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "    print(f\"Chi-square test for genre-topic association:\\nChi2 Statistic: {chi2}, p-value: {p}\")\n",
    "    return p < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591f75a-d5b5-4803-9361-8c943416e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 2: There are more profanities used now than in the 90s\n",
    "def test_profanity_over_time(df, profanity_list):\n",
    "    # Filter data for the 90s and recent songs\n",
    "    df['decade'] = np.where(df['Year'] < 2000, '90s', 'Recent')\n",
    "    # Count profanities\n",
    "    df['Profanity_count'] = df['Word_frequency'].apply(lambda freq: sum(freq.get(word, 0) for word in profanity_list))\n",
    "    profanity_counts = df.groupby('decade')['Profanity_count'].mean()\n",
    "    t_stat, p = ttest_ind(df[df['decade'] == '90s']['Profanity_count'], df[df['decade'] == 'Recent']['Profanity_count'])\n",
    "    print(f\"T-test for profanity usage:\\nT Statistic: {t_stat}, p-value: {p}\")\n",
    "    return p < 0.05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387059f5-5197-43b1-a25c-459f7d8c51b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 3: Hip Hop/Rap songs have richer vocabulary\n",
    "def test_vocabulary_richness(df):\n",
    "    # Filter to Hip Hop/Rap and other genres, then compare unique words\n",
    "    df_hiphop = df[df['Final_genre'] == 'Hip Hop/Rap']\n",
    "    df_other = df[df['Final_genre'] != 'Hip Hop/Rap']\n",
    "    t_stat, p = ttest_ind(df_hiphop['Unique_words'], df_other['Unique_words'])\n",
    "    print(f\"T-test for vocabulary richness in Hip Hop/Rap:\\nT Statistic: {t_stat}, p-value: {p}\")\n",
    "    return p < 0.05\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd11229-e1e6-4017-b1da-f8ebc89d7707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis 4: Some words are very frequent across all genres and times\n",
    "def test_common_words(df, threshold=0.05):\n",
    "    all_word_counts = Counter()\n",
    "    df['Word_frequency'].apply(lambda freq: all_word_counts.update(freq))\n",
    "    total_songs = len(df)\n",
    "    common_words = [word for word, count in all_word_counts.items() if count / total_songs > threshold]\n",
    "    print(f\"Common words across all genres and times: {common_words}\")\n",
    "    return common_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a958b33e-71ab-4b76-b65e-0f24ef2febd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tests\n",
    "profanity_list = ['fuck', 'shit', 'damn', 'bitch', 'ass', 'fucking', 'nigger', 'nigga', 'cunt', 'dick','asshole']  \n",
    "print(\"Hypothesis 1:\", \"Supported\" if test_genre_topic_association(df) else \"Not Supported\")\n",
    "print(\"Hypothesis 2:\", \"Supported\" if test_profanity_over_time(df, profanity_list) else \"Not Supported\")\n",
    "print(\"Hypothesis 3:\", \"Supported\" if test_vocabulary_richness(df) else \"Not Supported\")\n",
    "common_words = test_common_words(df)\n",
    "print(f\"Common words across all genres and times: {common_words}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
